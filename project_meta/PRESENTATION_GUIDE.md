# Presentation Outline: GA for Neural Network Hyperparameter Optimization

**Duration**: 15-20 minutes  
**Student**: Lojaine  
**Course**: Algorithmique MÃ©taheuristique - ISGA  
**Professor**: Pr. Oulad Sayad Younes

---

## ðŸŽ¯ SLIDE 1: Title Slide (30 seconds)

**Content**:
- Project Title: "Optimisation des HyperparamÃ¨tres d'un RÃ©seau de Neurones par Algorithme GÃ©nÃ©tique"
- Your name, class, academic year
- Course: Algorithmique MÃ©taheuristique

**What to say**:
> "Bonjour. Aujourd'hui, je vais vous prÃ©senter mon projet sur l'optimisation des hyperparamÃ¨tres 
> d'un rÃ©seau de neurones en utilisant un algorithme gÃ©nÃ©tique."

---

## ðŸ“Š SLIDE 2: Problem Introduction (2 minutes)

**Visual**: Show the challenge of hyperparameter tuning

**Content**:
- **The Challenge**: Neural networks have many hyperparameters
- Show search space calculation:
  - 4 choices for layers Ã— 5 for neurons Ã— continuous learning rate Ã— 4 batch sizes Ã— ...
  - = **Millions of possible combinations!**
- Traditional approaches:
  - Manual tuning: Time-consuming, not optimal
  - Grid search: Exhaustive, computationally expensive
  - Random search: Better but still inefficient

**What to say**:
> "Le problÃ¨me principal est le suivant: les rÃ©seaux de neurones ont de nombreux hyperparamÃ¨tres 
> Ã  configurer. Par exemple, combien de couches? Combien de neurones par couche? Quel taux 
> d'apprentissage? Cela crÃ©e un espace de recherche Ã©norme avec des millions de combinaisons 
> possibles. Les mÃ©thodes traditionnelles comme le grid search sont trop lentes."

---

## ðŸ§¬ SLIDE 3: Why Genetic Algorithm? (2 minutes)

**Visual**: GA advantages over other methods

**Content**:
- **Genetic Algorithms are ideal because**:
  1. âœ… Can handle large search spaces
  2. âœ… No gradient information needed
  3. âœ… Naturally balances exploration vs exploitation
  4. âœ… Can optimize multiple objectives (accuracy + speed + simplicity)
  5. âœ… Parallelizable (evaluate population in parallel)

- **Connection to biology**: Evolution, survival of the fittest

**What to say**:
> "Pourquoi utiliser un algorithme gÃ©nÃ©tique? Parce qu'il est particuliÃ¨rement bien adaptÃ© 
> Ã  ce type de problÃ¨me. Il peut explorer efficacement de grands espaces de recherche sans 
> avoir besoin de calculer des gradients, et il balance naturellement entre exploration de 
> nouvelles solutions et exploitation des bonnes solutions dÃ©jÃ  trouvÃ©es."

---

## ðŸ”¬ SLIDE 4: Methodology - Chromosome Encoding (2 minutes)

**Visual**: Show chromosome structure

**Content**:
```
Chromosome = {
    'n_layers': 2,
    'layer_sizes': [128, 64],
    'learning_rate': 0.001,
    'batch_size': 32,
    'dropout': 0.2,
    'optimizer': 'adam',
    'activation': 'relu'
}
```

- **7 genes** representing different hyperparameters
- Mix of discrete (layers, batch size) and continuous (learning rate, dropout)
- Each chromosome = one complete neural network configuration

**What to say**:
> "Voici comment nous encodons une solution. Chaque chromosome reprÃ©sente une configuration 
> complÃ¨te du rÃ©seau de neurones avec 7 gÃ¨nes diffÃ©rents: le nombre de couches, la taille 
> de chaque couche, le taux d'apprentissage, etc. C'est un mÃ©lange de paramÃ¨tres discrets 
> et continus."

---

## âš™ï¸ SLIDE 5: Fitness Function (2 minutes)

**Visual**: Fitness function formula and explanation

**Content**:
```
Fitness = 0.7 Ã— Accuracy + 0.2 Ã— Speed + 0.1 Ã— Simplicity

Where:
- Accuracy: Validation accuracy (most important - 70%)
- Speed: Normalized training time (20%)
- Simplicity: Model complexity/parameters (10%)
```

**Why these weights?**
- Accuracy is most important
- But we also want fast, efficient models
- Multi-objective optimization

**What to say**:
> "La fonction de fitness combine trois objectifs. L'accuracy est le plus important avec 70% 
> du poids, mais nous considÃ©rons aussi la vitesse d'entraÃ®nement (20%) et la simplicitÃ© du 
> modÃ¨le (10%). C'est une optimisation multi-objectif qui nous donne des modÃ¨les performants 
> mais aussi efficaces."

---

## ðŸ§¬ SLIDE 6: Genetic Operators (3 minutes)

**Visual**: Diagrams showing each operator

**Content**:

**1. Selection (Tournament)**
- Select k=3 random individuals
- Choose best among them
- Creates selection pressure

**2. Crossover (Uniform)**
- Take two parents
- For each gene, randomly choose from parent1 or parent2
- Rate: 80%

**3. Mutation**
- Randomly modify genes
- Discrete: random new value
- Continuous: small perturbation or complete reset
- Rate: 20%

**4. Elitism**
- Keep top 2 individuals unchanged
- Ensures we don't lose best solutions

**What to say**:
> "Nous utilisons quatre opÃ©rateurs gÃ©nÃ©tiques. D'abord la sÃ©lection par tournoi, oÃ¹ nous 
> choisissons les meilleurs parmi des groupes alÃ©atoires. Ensuite le crossover uniforme pour 
> combiner les parents. La mutation pour introduire de la diversitÃ© - avec des stratÃ©gies 
> diffÃ©rentes pour les paramÃ¨tres discrets et continus. Et finalement l'Ã©litisme pour garder 
> nos meilleures solutions."

---

## ðŸ’» SLIDE 7: Implementation Details (2 minutes)

**Visual**: Code structure diagram

**Content**:
- **Dataset**: Fashion-MNIST (28Ã—28 images, 10 classes)
- **GA Parameters**:
  - Population: 20 individuals
  - Generations: 15
  - Crossover rate: 0.8
  - Mutation rate: 0.2

- **Technology Stack**:
  - Python + TensorFlow/Keras
  - NumPy, Matplotlib
  - Streamlit (interface)

**What to say**:
> "Pour l'implÃ©mentation, nous utilisons le dataset Fashion-MNIST avec 60,000 images. 
> Notre population contient 20 individus et nous faisons Ã©voluer pendant 15 gÃ©nÃ©rations. 
> Le tout est codÃ© en Python avec TensorFlow pour les rÃ©seaux de neurones."

---

## ðŸ“ˆ SLIDE 8: Results - Fitness Evolution (3 minutes)

**Visual**: Show fitness evolution plot

**Content**:
- Graph showing:
  - Best fitness over generations
  - Average fitness over generations
  - Shows convergence around generation 8-10

**Key Observations**:
- Clear upward trend
- Convergence demonstrates GA is working
- Population diversity maintained

**What to say**:
> "Voici les rÃ©sultats de l'Ã©volution. Nous voyons clairement que le fitness s'amÃ©liore 
> au fil des gÃ©nÃ©rations. Le meilleur fitness commence Ã  environ 0.65 et atteint 0.85. 
> La convergence se produit autour de la gÃ©nÃ©ration 8-10, ce qui montre que l'algorithme 
> trouve efficacement de bonnes solutions."

---

## ðŸ† SLIDE 9: Best Solution Found (2 minutes)

**Visual**: Best hyperparameters + architecture diagram

**Content**:
**Best Configuration**:
```
- Layers: 3
- Architecture: [128, 64, 32]
- Learning Rate: 0.00234
- Batch Size: 64
- Dropout: 0.245
- Optimizer: Adam
- Activation: ReLU
```

**Performance**:
- Validation Accuracy: **88.5%**
- Training Time: 45 seconds
- Parameters: 125,000

**What to say**:
> "Voici la meilleure configuration trouvÃ©e par l'algorithme gÃ©nÃ©tique. Un rÃ©seau Ã  3 couches 
> avec 128, 64 et 32 neurones, un learning rate optimal de 0.00234, et l'activation ReLU. 
> Cette configuration atteint 88.5% d'accuracy en seulement 45 secondes d'entraÃ®nement."

---

## ðŸ“Š SLIDE 10: Comparison with Baselines (2 minutes)

**Visual**: Bar chart comparing methods

**Content**:

| Method | Accuracy | Time | Fitness |
|--------|----------|------|---------|
| **Genetic Algorithm** | **88.5%** | 45s | **0.85** |
| Random Search | 84.2% | 52s | 0.78 |
| Default Config | 82.1% | 38s | 0.76 |

**Key Findings**:
- âœ… GA outperforms both baselines in accuracy
- âœ… GA finds better overall balance (fitness)
- âœ… Demonstrates effectiveness of metaheuristic approach

**What to say**:
> "ComparÃ© aux mÃ©thodes de rÃ©fÃ©rence, l'algorithme gÃ©nÃ©tique trouve de meilleures solutions. 
> Il atteint 88.5% d'accuracy contre 84.2% pour la recherche alÃ©atoire et 82.1% pour la 
> configuration par dÃ©faut. Cela dÃ©montre l'efficacitÃ© de l'approche mÃ©taheuristique."

---

## ðŸŽ¨ SLIDE 11: Live Demo (Optional - 2 minutes)

**Option 1**: Show Streamlit interface
- Run 2-3 generations live
- Show real-time visualization

**Option 2**: Show pre-recorded video
- Full evolution in 30 seconds
- All visualizations

**What to say**:
> "Permettez-moi de vous montrer rapidement l'interface interactive que j'ai dÃ©veloppÃ©e. 
> Vous pouvez voir l'Ã©volution en temps rÃ©el, ajuster les paramÃ¨tres, et explorer les 
> rÃ©sultats de faÃ§on interactive."

---

## ðŸ’¡ SLIDE 12: Key Learnings & Challenges (2 minutes)

**Content**:

**What Worked Well**:
- âœ… GA effectively explored large search space
- âœ… Convergence was stable and predictable
- âœ… Multi-objective fitness balanced competing goals

**Challenges Faced**:
- âš ï¸ Training time (solved by reducing epochs for GA)
- âš ï¸ Balancing exploration vs exploitation
- âš ï¸ Choosing fitness function weights

**Improvements for Future**:
- Parallel fitness evaluation
- Adaptive mutation rates
- Transfer learning between runs

**What to say**:
> "Quelques apprentissages clÃ©s: l'algorithme gÃ©nÃ©tique a trÃ¨s bien explorÃ© l'espace de 
> recherche. Le principal dÃ©fi Ã©tait le temps d'entraÃ®nement - j'ai rÃ©solu cela en rÃ©duisant 
> le nombre d'epochs pendant l'Ã©volution. Pour de futures amÃ©liorations, on pourrait 
> parallÃ©liser l'Ã©valuation du fitness ou utiliser des taux de mutation adaptatifs."

---

## ðŸŽ“ SLIDE 13: Conclusion (1 minute)

**Content**:

**Summary**:
1. âœ… Successfully implemented GA for hyperparameter optimization
2. âœ… Demonstrated superiority over baseline methods
3. âœ… Combined metaheuristics with machine learning
4. âœ… Created interactive visualization and demo

**Impact**:
- Automated optimization saves time
- Better models than manual tuning
- Applicable to any ML problem

**Connection to Course**:
- Practical application of metaheuristic algorithms
- Shows power of nature-inspired optimization
- Combines theory with real-world problem

**What to say**:
> "En conclusion, ce projet dÃ©montre comment les algorithmes gÃ©nÃ©tiques peuvent rÃ©soudre 
> des problÃ¨mes d'optimisation complexes en machine learning. Nous avons rÃ©ussi Ã  automatiser 
> le processus de tuning et Ã  obtenir de meilleurs rÃ©sultats que les mÃ©thodes traditionnelles. 
> C'est une application concrÃ¨te des mÃ©taheuristiques enseignÃ©es dans ce cours."

---

## â“ SLIDE 14: Q&A (2-3 minutes)

**Anticipated Questions & Answers**:

**Q1: Why Fashion-MNIST instead of MNIST?**
> A: Fashion-MNIST is more challenging and interesting. MNIST is almost solved - even simple 
> models get 98%+. Fashion-MNIST better demonstrates the optimization capability.

**Q2: Why only 5 epochs during evolution?**
> A: To balance accuracy and computational time. We train the final best model with more epochs 
> (20+) for accurate evaluation.

**Q3: How do you prevent overfitting to the validation set?**
> A: Good question! The final model is evaluated on a separate test set. During GA, we use 
> validation for fitness but reserve test set for final evaluation.

**Q4: Why these specific fitness weights (0.7, 0.2, 0.1)?**
> A: Based on domain knowledge - accuracy is most important, but we want practical models. 
> These can be tuned based on specific requirements (e.g., embedded systems need more weight 
> on model size).

**Q5: How does this compare to Bayesian Optimization or AutoML?**
> A: GA is more interpretable and doesn't assume any structure in the search space. Bayesian 
> methods can be more sample-efficient but require more assumptions. This project focuses on 
> metaheuristic approach as per course requirements.

**Q6: What's the computational cost?**
> A: Population Ã— Generations Ã— Training time = 20 Ã— 15 Ã— ~45s = ~3.75 hours total. 
> Parallelization could reduce this significantly.

---

## ðŸ“‹ PRESENTATION TIPS

### Before Presentation:
- [ ] Test all code runs without errors
- [ ] Prepare backup (screenshots) in case of technical issues
- [ ] Practice timing (aim for 15-17 minutes for content + Q&A buffer)
- [ ] Have project files open and ready
- [ ] Test Streamlit app if doing live demo

### During Presentation:
- Speak clearly and confidently
- Make eye contact with professor and students
- Use technical terms correctly (from course)
- Be enthusiastic - show passion for the project
- Point to visualizations while explaining
- Don't read slides - explain in your own words

### Key Technical Terms to Use:
- MÃ©taheuristique
- Algorithme gÃ©nÃ©tique
- Fonction de fitness
- SÃ©lection par tournoi
- Crossover uniforme
- Mutation adaptative
- Ã‰litisme
- Convergence
- DiversitÃ© de population
- Optimisation multi-objectif

---

## ðŸŽ¯ SUCCESS CRITERIA

Your presentation will be successful if:
- âœ… Clearly explains the problem
- âœ… Demonstrates GA understanding
- âœ… Shows working implementation
- âœ… Presents meaningful results
- âœ… Compares with baselines
- âœ… Handles questions confidently
- âœ… Stays within time limit
- âœ… Engages the audience

---

**Good luck with your presentation! You've got this! ðŸš€**
