"""
OPTIMISATION D'HYPERPARAM√àTRES PAR ALGORITHME G√âN√âTIQUE
Version compl√®te avec commentaires d√©taill√©s pour pr√©sentation

Ce programme utilise un algorithme g√©n√©tique pour trouver automatiquement
les meilleurs hyperparam√®tres pour un r√©seau de neurones sur Fashion-MNIST.
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers
import matplotlib.pyplot as plt
import time
import random
from copy import deepcopy
import gc
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ============================================================
# CONFIGURATION INITIALE
# ============================================================

# Force l'utilisation du CPU pour √©viter les probl√®mes de m√©moire GPU
# Ceci est essentiel car nous allons entra√Æner beaucoup de mod√®les successivement
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

print("="*70)
print("üß¨ ALGORITHME G√âN√âTIQUE POUR OPTIMISATION D'HYPERPARAM√àTRES")
print("="*70)

# Fixe les seeds pour la reproductibilit√© des r√©sultats
# Cela permet d'obtenir les m√™mes r√©sultats √† chaque ex√©cution
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

# Cr√©e un dossier pour sauvegarder tous les r√©sultats
# Le timestamp permet d'avoir un dossier unique pour chaque ex√©cution
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
results_dir = f'results_{timestamp}'
os.makedirs(results_dir, exist_ok=True)
os.makedirs(f'{results_dir}/plots', exist_ok=True)
print(f"üìÅ Les r√©sultats seront sauvegard√©s dans: {results_dir}/\n")

# ============================================================
# CLASSE ALGORITHME G√âN√âTIQUE
# ============================================================

class GeneticAlgorithm:
    """
    Impl√©mentation d'un algorithme g√©n√©tique pour l'optimisation d'hyperparam√®tres.
    
    L'algorithme g√©n√©tique fonctionne en 5 √©tapes principales:
    1. Initialisation: Cr√©er une population al√©atoire
    2. √âvaluation: Calculer le fitness de chaque individu
    3. S√©lection: Choisir les meilleurs parents
    4. Croisement: Combiner les parents pour cr√©er des enfants
    5. Mutation: Modifier l√©g√®rement certains enfants
    """
    
    def __init__(self, population_size=10, generations=8):
        """
        Initialise l'algorithme g√©n√©tique.
        
        Args:
            population_size: Nombre d'individus dans chaque g√©n√©ration (10 individus)
            generations: Nombre de g√©n√©rations √† ex√©cuter (8 g√©n√©rations)
        
        Avec ces param√®tres, nous allons entra√Æner 10 √ó 8 = 80 r√©seaux de neurones
        """
        self.population_size = population_size
        self.generations = generations
        self.population = []  # Liste qui contiendra tous les individus actuels
        self.history = []     # Liste qui stocke l'historique de chaque g√©n√©ration
        self.best_individual = None  # Meilleure solution trouv√©e
        self.best_fitness = -float('inf')  # Meilleur fitness trouv√©
        
        # ESPACE DE RECHERCHE
        # D√©finit tous les hyperparam√®tres possibles que l'AG peut explorer
        # C'est l'√©quivalent du "g√©notype" en biologie
        self.search_space = {
            'n_layers': [1, 2, 3],  # Nombre de couches cach√©es (1 √† 3)
            'layer_sizes': [32, 64, 128, 256],  # Taille de chaque couche (nombre de neurones)
            'learning_rate': (0.0001, 0.01),  # Taux d'apprentissage (valeur continue)
            'batch_size': [32, 64],  # Taille du batch pour l'entra√Ænement
            'dropout': (0.0, 0.4),  # Taux de dropout pour la r√©gularisation (valeur continue)
            'optimizer': ['adam', 'sgd', 'rmsprop'],  # Algorithme d'optimisation
            'activation': ['relu', 'tanh', 'sigmoid']  # Fonction d'activation
        }
    
    def create_random_chromosome(self):
        """
        Cr√©e un chromosome al√©atoire (un individu).
        
        Un chromosome repr√©sente une configuration compl√®te d'hyperparam√®tres.
        C'est comme un "ADN" qui encode toutes les caract√©ristiques du r√©seau.
        
        Returns:
            dict: Un dictionnaire contenant tous les hyperparam√®tres
        """
        # Choisit d'abord le nombre de couches
        n_layers = random.choice(self.search_space['n_layers'])
        
        # Cr√©e un chromosome avec tous les hyperparam√®tres
        return {
            'n_layers': n_layers,
            # G√©n√®re une liste de tailles de couches (une taille par couche)
            'layer_sizes': [random.choice(self.search_space['layer_sizes']) 
                           for _ in range(n_layers)],
            # Learning rate: valeur continue entre min et max
            'learning_rate': random.uniform(*self.search_space['learning_rate']),
            'batch_size': random.choice(self.search_space['batch_size']),
            # Dropout: valeur continue entre 0 et 0.4
            'dropout': random.uniform(*self.search_space['dropout']),
            'optimizer': random.choice(self.search_space['optimizer']),
            'activation': random.choice(self.search_space['activation'])
        }
    
    def initialize_population(self):
        """
        √âTAPE 1: Initialisation de la population.
        
        Cr√©e la population initiale avec des individus al√©atoires.
        C'est la g√©n√©ration 0, le point de d√©part de l'√©volution.
        """
        self.population = [self.create_random_chromosome() 
                          for _ in range(self.population_size)]
    
    def tournament_selection(self, fitness_scores):
        """
        √âTAPE 3: S√©lection par tournoi.
        
        S√©lectionne un parent en faisant un "tournoi" entre 3 individus al√©atoires.
        Le meilleur des 3 gagne et devient parent.
        
        Cette m√©thode donne plus de chances aux bons individus d'√™tre s√©lectionn√©s,
        mais permet aussi √† des moins bons d'avoir une chance (diversit√©).
        
        Args:
            fitness_scores: Liste des fitness de tous les individus
            
        Returns:
            dict: Copie du chromosome s√©lectionn√©
        """
        tournament_size = 3  # Taille du tournoi: on compare 3 individus
        # Choisit 3 individus au hasard
        indices = random.sample(range(len(self.population)), tournament_size)
        # Trouve celui qui a le meilleur fitness
        best_idx = max(indices, key=lambda idx: fitness_scores[idx])
        # Retourne une copie pour ne pas modifier l'original
        return deepcopy(self.population[best_idx])
    
    def crossover(self, parent1, parent2):
        """
        √âTAPE 4: Croisement (crossover).
        
        Combine deux parents pour cr√©er un enfant.
        Pour chaque hyperparam√®tre, on choisit al√©atoirement s'il vient du parent1 ou parent2.
        C'est l'√©quivalent de la reproduction sexu√©e en biologie.
        
        Args:
            parent1: Premier parent (chromosome)
            parent2: Deuxi√®me parent (chromosome)
            
        Returns:
            dict: Enfant cr√©√© (nouveau chromosome)
        """
        child = {}
        
        # Pour chaque hyperparam√®tre, choisit al√©atoirement le parent
        for key in parent1.keys():
            # 50% de chance de prendre la valeur du parent1, 50% du parent2
            child[key] = deepcopy(parent1[key] if random.random() < 0.5 else parent2[key])
        
        # CAS SP√âCIAL: Ajuste layer_sizes pour correspondre √† n_layers
        # Si on a h√©rit√© 2 couches mais 3 tailles, il faut corriger
        n_layers = child['n_layers']
        if len(child['layer_sizes']) != n_layers:
            if len(child['layer_sizes']) < n_layers:
                # Ajoute des couches manquantes
                while len(child['layer_sizes']) < n_layers:
                    child['layer_sizes'].append(random.choice(self.search_space['layer_sizes']))
            else:
                # Retire les couches en trop
                child['layer_sizes'] = child['layer_sizes'][:n_layers]
        
        return child
    
    def mutate(self, chromosome):
        """
        √âTAPE 5: Mutation.
        
        Modifie al√©atoirement certains g√®nes du chromosome.
        Cela permet d'explorer de nouvelles solutions et √©viter de rester coinc√©
        dans un optimum local.
        
        Args:
            chromosome: Chromosome √† muter
            
        Returns:
            dict: Chromosome mut√©
        """
        mutated = deepcopy(chromosome)
        mutation_rate = 0.3  # 30% de chance de mutation pour chaque g√®ne
        
        # Pour chaque hyperparam√®tre
        for key in mutated.keys():
            # 30% de chance de muter ce g√®ne
            if random.random() < mutation_rate:
                # Diff√©rentes strat√©gies selon le type d'hyperparam√®tre
                if key == 'n_layers':
                    # Mutation du nombre de couches
                    old_n = mutated['n_layers']
                    mutated['n_layers'] = random.choice(self.search_space['n_layers'])
                    new_n = mutated['n_layers']
                    # Ajuste layer_sizes en cons√©quence
                    if new_n > old_n:
                        mutated['layer_sizes'].extend([
                            random.choice(self.search_space['layer_sizes'])
                            for _ in range(new_n - old_n)
                        ])
                    elif new_n < old_n:
                        mutated['layer_sizes'] = mutated['layer_sizes'][:new_n]
                
                elif key == 'layer_sizes' and len(mutated['layer_sizes']) > 0:
                    # Mutation d'une taille de couche al√©atoire
                    idx = random.randint(0, len(mutated['layer_sizes']) - 1)
                    mutated['layer_sizes'][idx] = random.choice(self.search_space['layer_sizes'])
                
                elif key == 'learning_rate':
                    # Nouvelle valeur al√©atoire pour le learning rate
                    mutated['learning_rate'] = random.uniform(*self.search_space['learning_rate'])
                
                elif key == 'batch_size':
                    mutated['batch_size'] = random.choice(self.search_space['batch_size'])
                
                elif key == 'dropout':
                    # Nouvelle valeur al√©atoire pour le dropout
                    mutated['dropout'] = random.uniform(*self.search_space['dropout'])
                
                elif key == 'optimizer':
                    mutated['optimizer'] = random.choice(self.search_space['optimizer'])
                
                elif key == 'activation':
                    mutated['activation'] = random.choice(self.search_space['activation'])
        
        return mutated
    
    def evolve(self, fitness_function):
        """
        BOUCLE PRINCIPALE: Fait √©voluer la population sur plusieurs g√©n√©rations.
        
        C'est ici que tout se passe! L'algorithme:
        1. Initialise la population
        2. Pour chaque g√©n√©ration:
           - √âvalue tous les individus
           - S√©lectionne les meilleurs
           - Cr√©e une nouvelle g√©n√©ration par croisement et mutation
        
        Args:
            fitness_function: Fonction qui √©value un chromosome et retourne son fitness
            
        Returns:
            tuple: (meilleur_chromosome, meilleur_fitness)
        """
        # √âTAPE 1: Cr√©e la population initiale
        self.initialize_population()
        
        # BOUCLE SUR LES G√âN√âRATIONS
        for generation in range(self.generations):
            print(f"\n{'='*70}")
            print(f"G√âN√âRATION {generation + 1}/{self.generations}")
            print(f"{'='*70}")
            
            fitness_scores = []  # Stocke le fitness de chaque individu
            gen_details = []     # Stocke les d√©tails complets de cette g√©n√©ration
            
            # √âTAPE 2: √âVALUATION - Calcule le fitness de chaque individu
            for idx, chromosome in enumerate(self.population):
                print(f"\nüß¨ Individu {idx + 1}/{self.population_size}")
                
                # Appelle la fonction fitness (qui va entra√Æner un r√©seau de neurones)
                result = fitness_function(chromosome)
                fitness = result['fitness']
                fitness_scores.append(fitness)
                
                # Sauvegarde les d√©tails pour l'historique
                gen_details.append({
                    'individual': idx + 1,
                    'chromosome': chromosome,
                    **result
                })
                
                # Met √† jour le meilleur individu si n√©cessaire
                if fitness > self.best_fitness:
                    self.best_fitness = fitness
                    self.best_individual = deepcopy(chromosome)
            
            # STATISTIQUES DE LA G√âN√âRATION
            best_fit = max(fitness_scores)    # Meilleur fitness de cette g√©n√©ration
            avg_fit = np.mean(fitness_scores)  # Fitness moyen
            worst_fit = min(fitness_scores)   # Pire fitness
            
            print(f"\nüìä R√©sum√© G√©n√©ration {generation + 1}:")
            print(f"   Meilleur Fitness: {best_fit:.4f}")
            print(f"   Fitness Moyen:    {avg_fit:.4f}")
            print(f"   Pire Fitness:     {worst_fit:.4f}")
            
            # Sauvegarde dans l'historique
            self.history.append({
                'generation': generation + 1,
                'best_fitness': float(best_fit),
                'avg_fitness': float(avg_fit),
                'worst_fitness': float(worst_fit),
                'std_fitness': float(np.std(fitness_scores)),
                'best_chromosome': self.population[np.argmax(fitness_scores)],
                'details': gen_details
            })
            
            # CR√âATION DE LA NOUVELLE G√âN√âRATION (sauf pour la derni√®re)
            if generation < self.generations - 1:
                new_population = []
                
                # √âLITISME: Garde les 2 meilleurs individus intacts
                # Cela garantit que les bonnes solutions ne sont jamais perdues
                elite_indices = np.argsort(fitness_scores)[-2:]
                for idx in elite_indices:
                    new_population.append(deepcopy(self.population[idx]))
                
                # Cr√©e le reste de la nouvelle population
                while len(new_population) < self.population_size:
                    # S√âLECTION: Choisit deux parents
                    parent1 = self.tournament_selection(fitness_scores)
                    parent2 = self.tournament_selection(fitness_scores)
                    
                    # CROISEMENT: 80% de chance de faire un croisement
                    if random.random() < 0.8:
                        child = self.crossover(parent1, parent2)
                    else:
                        child = deepcopy(parent1)  # Sinon, copie simple du parent
                    
                    # MUTATION: 30% de chance de muter l'enfant
                    if random.random() < 0.3:
                        child = self.mutate(child)
                    
                    new_population.append(child)
                
                # Remplace l'ancienne population par la nouvelle
                self.population = new_population
        
        # Retourne la meilleure solution trouv√©e sur toutes les g√©n√©rations
        return self.best_individual, self.best_fitness

# ============================================================
# ENTRA√éNEMENT DES R√âSEAUX DE NEURONES - AVEC GESTION M√âMOIRE
# ============================================================

def train_model(config, X_train, y_train, X_val, y_val, epochs=10):
    """
    Entra√Æne un r√©seau de neurones avec une configuration donn√©e.
    
    Cette fonction est appel√©e par l'AG pour √©valuer chaque individu.
    Elle:
    1. Construit un r√©seau selon les hyperparam√®tres
    2. L'entra√Æne sur les donn√©es
    3. Retourne le fitness (= accuracy de validation)
    
    Args:
        config: Configuration des hyperparam√®tres (chromosome)
        X_train, y_train: Donn√©es d'entra√Ænement
        X_val, y_val: Donn√©es de validation
        epochs: Nombre d'epochs d'entra√Ænement
        
    Returns:
        dict: R√©sultats (fitness, accuracy, temps, nombre de param√®tres)
    """
    
    # IMPORTANT: Nettoie la m√©moire avant de commencer
    # Sans √ßa, TensorFlow accumule les mod√®les en m√©moire et √ßa plante!
    keras.backend.clear_session()
    gc.collect()
    
    try:
        # CONSTRUCTION DU MOD√àLE selon le chromosome
        
        # Couche d'entr√©e: aplatit les images 28√ó28 en vecteur de 784
        model = models.Sequential([layers.Flatten(input_shape=(28, 28))])
        
        # Ajoute les couches cach√©es selon n_layers et layer_sizes
        for i in range(config['n_layers']):
            # Couche dense avec activation
            model.add(layers.Dense(
                config['layer_sizes'][i], 
                activation=config['activation']
            ))
            # Dropout pour r√©gularisation (si > 0)
            if config['dropout'] > 0:
                model.add(layers.Dropout(config['dropout']))
        
        # Couche de sortie: 10 neurones (10 classes) avec softmax
        model.add(layers.Dense(10, activation='softmax'))
        
        # CHOIX DE L'OPTIMIZER selon le chromosome
        if config['optimizer'] == 'adam':
            opt = optimizers.Adam(learning_rate=config['learning_rate'])
        elif config['optimizer'] == 'sgd':
            opt = optimizers.SGD(learning_rate=config['learning_rate'], momentum=0.9)
        else:
            opt = optimizers.RMSprop(learning_rate=config['learning_rate'])
        
        # Compilation du mod√®le
        model.compile(
            optimizer=opt,
            loss='categorical_crossentropy',  # Pour classification multi-classes
            metrics=['accuracy']
        )
        
        # ENTRA√éNEMENT DU MOD√àLE
        start_time = time.time()
        history = model.fit(
            X_train, y_train,
            batch_size=config['batch_size'],
            epochs=epochs,
            validation_data=(X_val, y_val),
            verbose=0  # Pas d'affichage pour ne pas polluer la sortie
        )
        train_time = time.time() - start_time
        
        # EXTRACTION DES M√âTRIQUES
        val_acc = float(history.history['val_accuracy'][-1])   # Accuracy validation
        train_acc = float(history.history['accuracy'][-1])     # Accuracy entra√Ænement
        n_params = int(model.count_params())                   # Nombre de param√®tres
        
        # CALCUL DU FITNESS
        # Ici, on utilise simplement l'accuracy de validation
        # On pourrait aussi p√©naliser les mod√®les trop complexes ou trop lents
        fitness = val_acc
        
        # Affiche un r√©sum√©
        print(f"   Config: {config['n_layers']}√ó{config['layer_sizes']}, "
              f"{config['optimizer']}, lr={config['learning_rate']:.5f}")
        print(f"   R√©sultat: Train={train_acc:.4f}, Val={val_acc:.4f}, "
              f"Temps={train_time:.1f}s")
        
        # Pr√©pare le r√©sultat
        result = {
            'fitness': float(fitness),
            'accuracy': float(val_acc),
            'train_accuracy': float(train_acc),
            'training_time': float(train_time),
            'n_parameters': int(n_params)
        }
        
        # NETTOYAGE CRITIQUE: Supprime le mod√®le et lib√®re la m√©moire
        del model, history
        keras.backend.clear_session()
        gc.collect()
        
        return result
        
    except Exception as e:
        # En cas d'erreur, retourne un fitness de 0
        print(f"   ‚ùå Entra√Ænement √©chou√©: {str(e)}")
        keras.backend.clear_session()
        gc.collect()
        
        return {
            'fitness': 0.0,
            'accuracy': 0.0,
            'train_accuracy': 0.0,
            'training_time': 0.0,
            'n_parameters': 0
        }

# ============================================================
# CHARGEMENT DES DONN√âES
# ============================================================

print("\nüì¶ Chargement de Fashion-MNIST...")

# Fashion-MNIST: 70,000 images de v√™tements (28√ó28 pixels, 10 classes)
# Classes: T-shirt, Pantalon, Pull, Robe, Manteau, Sandale, Chemise, Basket, Sac, Bottine
(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()

# Utilise un sous-ensemble pour acc√©l√©rer le calcul
# En production, on utiliserait le dataset complet (60,000)
X_train = X_train_full[:5000].astype('float32') / 255.0  # Normalise entre 0 et 1
y_train = y_train_full[:5000]
X_val = X_train_full[5000:6000].astype('float32') / 255.0
y_val = y_train_full[5000:6000]

# Convertit les labels en one-hot encoding
# Ex: 3 devient [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
y_train = keras.utils.to_categorical(y_train, 10)
y_val = keras.utils.to_categorical(y_val, 10)

print(f"‚úÖ Dataset: {len(X_train)} entra√Ænement, {len(X_val)} validation")

# ============================================================
# EX√âCUTION DE L'ALGORITHME G√âN√âTIQUE
# ============================================================

print("\nüß¨ D√©marrage de l'Algorithme G√©n√©tique...")
print("Param√®tres: 10 individus √ó 8 g√©n√©rations = 80 √©valuations")
print("Temps estim√©: ~30-40 minutes\n")

# Initialise l'AG avec 10 individus et 8 g√©n√©rations
ga = GeneticAlgorithm(population_size=10, generations=8)

# D√©finit la fonction fitness: simplement appeler train_model
def fitness_func(chromosome):
    return train_model(chromosome, X_train, y_train, X_val, y_val, epochs=10)

# LANCE L'√âVOLUTION!
# C'est ici que tout se passe: 80 r√©seaux vont √™tre entra√Æn√©s
best_chromosome, best_fitness = ga.evolve(fitness_func)

# Sauvegarde l'historique complet en JSON
with open(f'{results_dir}/ga_history.json', 'w') as f:
    json.dump(ga.history, f, indent=2, default=str)

# ============================================================
# ENTRA√éNEMENT DU MOD√àLE FINAL
# ============================================================

print("\n" + "="*70)
print("üèÜ MEILLEURE SOLUTION TROUV√âE")
print("="*70)
print(f"\nMeilleur Fitness: {best_fitness:.4f}\n")
print("Meilleurs Hyperparam√®tres:")
for key, value in best_chromosome.items():
    print(f"  {key:15s}: {value}")

# Entra√Æne le meilleur mod√®le avec plus d'epochs pour des r√©sultats finaux
print("\nüéØ Entra√Ænement du mod√®le final avec 20 epochs...")
final_result = train_model(best_chromosome, X_train, y_train, X_val, y_val, epochs=20)

print(f"\n‚úÖ Performance du Mod√®le Final:")
print(f"   Accuracy Validation: {final_result['accuracy']:.4f}")
print(f"   Temps d'Entra√Ænement: {final_result['training_time']:.2f}s")
print(f"   Nombre de Param√®tres: {final_result['n_parameters']:,}")

# ============================================================
# COMPARAISONS AVEC LES BASELINES
# ============================================================

print("\n" + "="*70)
print("üìä COMPARAISONS AVEC LES M√âTHODES DE BASE")
print("="*70)

# BASELINE 1: Recherche Al√©atoire
# Teste 5 configurations al√©atoires (sans AG)
print("\nüé≤ Recherche Al√©atoire (5 essais)...")
random_results = []
for i in range(5):
    print(f"\n  Essai {i+1}/5")
    config = ga.create_random_chromosome()  # Configuration al√©atoire
    result = train_model(config, X_train, y_train, X_val, y_val, epochs=10)
    random_results.append(result)

# Garde le meilleur r√©sultat al√©atoire
best_random = max(random_results, key=lambda x: x['accuracy'])

# BASELINE 2: Configuration par D√©faut
# Teste une configuration "standard" souvent utilis√©e
print("\nüìã Configuration par D√©faut...")
default_config = {
    'n_layers': 2,
    'layer_sizes': [128, 64],
    'learning_rate': 0.001,
    'batch_size': 32,
    'dropout': 0.2,
    'optimizer': 'adam',
    'activation': 'relu'
}
default_result = train_model(default_config, X_train, y_train, X_val, y_val, epochs=10)

# COMPILATION DES R√âSULTATS
comparison = {
    'Genetic Algorithm': {
        'fitness': float(best_fitness),
        'accuracy': float(final_result['accuracy']),
        'training_time': float(final_result['training_time']),
        'n_parameters': int(final_result['n_parameters'])
    },
    'Random Search': {
        'fitness': float(best_random['fitness']),
        'accuracy': float(best_random['accuracy']),
        'training_time': float(best_random['training_time']),
        'n_parameters': int(best_random['n_parameters'])
    },
    'Default Config': {
        'fitness': float(default_result['fitness']),
        'accuracy': float(default_result['accuracy']),
        'training_time': float(default_result['training_time']),
        'n_parameters': int(default_result['n_parameters'])
    }
}

# Sauvegarde en JSON
with open(f'{results_dir}/comparison.json', 'w') as f:
    json.dump(comparison, f, indent=2)

# AFFICHAGE DU TABLEAU COMPARATIF
print("\n" + "="*70)
print("COMPARAISON FINALE DES M√âTHODES")
print("="*70)
print(f"{'M√©thode':<20} {'Accuracy':>12} {'Param√®tres':>15}")
print("-"*70)
for method, metrics in comparison.items():
    print(f"{method:<20} {metrics['accuracy']:>12.4f} {metrics['n_parameters']:>15,}")

print("="*70)

# VERDICT
if comparison['Genetic Algorithm']['accuracy'] > comparison['Random Search']['accuracy']:
    improvement = (comparison['Genetic Algorithm']['accuracy'] - 
                  comparison['Random Search']['accuracy']) * 100
    print(f"\n‚úÖ SUCC√àS: L'AG a trouv√© une solution {improvement:.1f}% meilleure!")
else:
    print("\n‚ö†Ô∏è  L'AG √©tait comp√©titif avec la recherche al√©atoire")

# ============================================================
# CR√âATION DES VISUALISATIONS
# ============================================================

print("\nüìä Cr√©ation des visualisations...")

# GRAPHIQUE 1: √âvolution du Fitness
# Montre comment le fitness s'am√©liore sur les g√©n√©rations
generations = [h['generation'] for h in ga.history]
best_fitness_list = [h['best_fitness'] for h in ga.history]
avg_fitness_list = [h['avg_fitness'] for h in ga.history]

plt.figure(figsize=(10, 6))
plt.plot(generations, best_fitness_list, 'o-', 
         label='Meilleur Fitness', linewidth=2, markersize=8, color='#2E86DE')
plt.plot(generations, avg_fitness_list, 's-', 
         label='Fitness Moyen', linewidth=2, markersize=6, color='#EE5A6F')
plt.xlabel('G√©n√©ration', fontsize=12)
plt.ylabel('Fitness (Accuracy de Validation)', fontsize=12)
plt.title('√âvolution du Fitness sur les G√©n√©rations', fontsize=14, fontweight='bold')
plt.legend(fontsize=10)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig(f'{results_dir}/plots/fitness_evolution.png', dpi=300)
plt.close()

# GRAPHIQUE 2: Comparaison des M√©thodes
# Barres pour comparer GA vs Random Search vs Default
methods = list(comparison.keys())
accuracies = [comparison[m]['accuracy'] for m in methods]

plt.figure(figsize=(10, 6))
bars = plt.bar(methods, accuracies, color=['#FF6B6B', '#4ECDC4', '#95E1D3'])
plt.ylabel('Accuracy', fontsize=12)
plt.title('Comparaison des M√©thodes', fontsize=14, fontweight='bold')
plt.ylim([0, 1.0])
# Ajoute les valeurs au-dessus des barres
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
            f'{height:.4f}', ha='center', va='bottom', fontweight='bold')
plt.tight_layout()
plt.savefig(f'{results_dir}/plots/comparison.png', dpi=300)
plt.close()

print(f"‚úÖ Visualisations sauvegard√©es dans {results_dir}/plots/")

# ============================================================
# CONCLUSION
# ============================================================

print("\n" + "="*70)
print("‚ú® PROJET TERMIN√â AVEC SUCC√àS!")
print("="*70)
print(f"\nüìÅ Tous les r√©sultats sont dans: {results_dir}/")
print(f"   - ga_history.json       : Historique complet de l'√©volution")
print(f"   - comparison.json       : Comparaison avec les baselines")
print(f"   - plots/fitness_evolution.png : Graphique d'√©volution")
print(f"   - plots/comparison.png  : Graphique de comparaison")
print("\n" + "="*70)
print("üéì Projet M√©taheuristiques - ISGA Marrakech 2024-2025")
print("="*70)